{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "from matplotlib import pyplot as plt\n",
    "import networkx as nx\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# install R and dagitty first: install.packages(\"dagitty\")\n",
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects.packages import importr\n",
    "\n",
    "# Import R's dagitty\n",
    "dagitty = importr('dagitty')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# functions\n",
    "def sim_weight(lengths, sd, beta_w):\n",
    "    random_variation = np.random.normal(0, sd, len(lengths))  # random noise\n",
    "    weights = beta_w*lengths + random_variation\n",
    "    return weights\n",
    "\n",
    "def sim_colour(lengths, sd, beta_c):\n",
    "    random_variation = np.random.normal(0, sd, len(lengths))  # random noise\n",
    "    colour = beta_c*lengths + random_variation\n",
    "    return colour\n",
    "\n",
    "def sim_predation(colours, weights, sd, beta_c, beta_w):\n",
    "    random_variation = np.random.normal(0, sd, len(colours))  # random noise\n",
    "    predation = beta_c*colours + beta_w*weights + random_variation\n",
    "    return predation\n",
    "\n",
    "def sim_reproduction(colours, weights, sd, beta_c, beta_w):\n",
    "    random_variation = np.random.normal(0, sd, len(colours))  # random noise\n",
    "    reproduction = beta_c*colours + beta_w*weights + random_variation\n",
    "    return reproduction\n",
    "\n",
    "def standardize(x):\n",
    "    return zscore(x)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3 - Underfitting, Overfitting, Predictive Accuracy and Model Comparison\n",
    "\n",
    "**Author:** Arun Oakley-Cogan  \n",
    "**Date:** 2025-10-06"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "np.random.seed(123) \n",
    "# create frog data set\n",
    "# number of frogs\n",
    "n_frog = 75\n",
    "# generate some lengths\n",
    "lengths = np.random.normal(0, 1, n_frog)\n",
    "# Length -> Weight\n",
    "weights = sim_weight(lengths, 1, 1)\n",
    "# Length -> Colour\n",
    "colours = sim_colour(lengths, 1, -1)\n",
    "# colour -> predation, weight -> predation\n",
    "predation = sim_predation(colours, weights, sd=1, beta_c=1.5, beta_w=1)\n",
    "# colour -> reproduction, weight->reproduction\n",
    "reproduction = sim_reproduction(colours, weights, sd=1, beta_c=-1.5, beta_w=1)\n",
    "\n",
    "frog_data = {\n",
    "    'weights': standardize(weights),\n",
    "    'lengths': standardize(lengths),\n",
    "    'colours': standardize(colours),\n",
    "    'reproduction': standardize(reproduction),\n",
    "    'predation': standardize(predation)\n",
    "}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# draw dag\n",
    "dag = dagitty.dagitty(\"dag{ Length -> Weight Length -> Colour Colour-> Reproduction Colour->Predation Weight->Predation Weight->Reproduction}\")\n",
    "\n",
    "# extract edges for Python plotting\n",
    "edges_r = ro.r('function(d) { e <- edges(d); data.frame(from=e$v, to=e$w) }')(dag)\n",
    "edges = [(str(edges_r[0][i]), str(edges_r[1][i])) for i in range(len(edges_r[0]))]\n",
    "\n",
    "dag_nx = nx.DiGraph(edges)\n",
    "# set coordinates\n",
    "pos = {\n",
    "    'Colour': (0, 0),\n",
    "    'Length': (0, 1),\n",
    "    'Reproduction': (1, 0),\n",
    "    'Weight': (1, 1),\n",
    "    'Predation': (0.5, 0.5)\n",
    "}\n",
    "# draw dag\n",
    "nx.draw(dag_nx, pos, with_labels=True, node_color='lightblue',\n",
    "        node_size=1500, arrowsize=20, arrows=True)\n",
    "plt.title(\"Collider DAG: Predation as collider\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have looked at the way statistical models can:\n",
    "\n",
    "-   Describe the points in our data by fitting a model (linear regression)\n",
    "\n",
    "-   Describe what function explains these points (causal inference)\n",
    "\n",
    "We can also use statistical models to aid in *prediction*. What is going to be the next observation from the same process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is LPPD?\n",
    "\n",
    "**LPPD** stands for **Log Pointwise Predictive Density**. It's a measure of how well a model predicts data, and it's fundamental to modern Bayesian model comparison.\n",
    "\n",
    "When we fit a Bayesian model, we get a **posterior distribution** of parameters.\n",
    "\n",
    "LPPD can answer, \"How well does this posterior distribution predict each observation in our data?\"\n",
    "\n",
    "For each data point $y_i$, LPPD calculates:\n",
    "\n",
    "$$\\text{lppd} = \\sum_{i=1}^{N} \\log \\left( \\frac{1}{S} \\sum_{s=1}^{S} p(y_i | \\theta_s) \\right)$$\n",
    "\n",
    "Where: \n",
    "- $N$ is the number of observations \n",
    "- $S$ is the number of posterior samples \n",
    "- $\\theta_s$ is the $s^{th}$ sample from the posterior \n",
    "- $p(y_i | \\theta_s)$ is the likelihood of observation $i$ given parameters $\\theta_s$\n",
    "\n",
    "For each observation, we average the likelihood across all posterior samples, take the log, and sum across all observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important for...\n",
    "\n",
    "1.  **Prediction focus**: LPPD measures predictive accuracy, not just fit\n",
    "2.  **Accounts for uncertainty**: Uses the full posterior distribution, not just point estimates\n",
    "3.  **Foundation for model comparison**: LPPD is the basis for WAIC and LOO-CV\n",
    "4.  **Detects overfitting**: Models that overfit will have high in-sample LPPD but poor out-of-sample LPPD\n",
    "\n",
    "Let's use our simulated data to show it in action"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Model 1: Intercept only\n",
    "with pm.Model() as one_par:\n",
    "    # priors\n",
    "    alpha = pm.Normal(\"alpha\", 0, 1)\n",
    "    sigma = pm.Exponential(\"sigma\", 1)\n",
    "    \n",
    "    # linear model\n",
    "    mu = pm.Deterministic(\"mu\", alpha)\n",
    "    \n",
    "    # data likelihood\n",
    "    predation_obs = pm.Normal(\"predation\", mu, sigma, observed=frog_data['predation'])\n",
    "    \n",
    "    one_par_idata = pm.sample(chains=4, idata_kwargs={\"log_likelihood\": True})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Model 2: Colour only\n",
    "with pm.Model() as two_par:\n",
    "    # priors\n",
    "    alpha = pm.Normal(\"alpha\", 0, 1)\n",
    "    beta_c = pm.Normal(\"beta_c\", 0, 1)\n",
    "    sigma = pm.Exponential(\"sigma\", 1)\n",
    "    \n",
    "    # linear model\n",
    "    mu = pm.Deterministic(\"mu\", alpha + beta_c*frog_data['colours'])\n",
    "    \n",
    "    # data likelihood\n",
    "    predation_obs = pm.Normal(\"predation\", mu, sigma, observed=frog_data['predation'])\n",
    "    \n",
    "    two_par_idata = pm.sample(chains=4, idata_kwargs={\"log_likelihood\": True})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Model 3: Colour + Length\n",
    "with pm.Model() as three_par:\n",
    "    # priors\n",
    "    alpha = pm.Normal(\"alpha\", 0, 1)\n",
    "    beta_c = pm.Normal(\"beta_c\", 0, 1)\n",
    "    beta_l = pm.Normal(\"beta_l\", 0, 1)\n",
    "    sigma = pm.Exponential(\"sigma\", 1)\n",
    "    \n",
    "    # linear model\n",
    "    mu = pm.Deterministic(\"mu\", alpha + beta_c*frog_data['colours'] + beta_l*frog_data['lengths'])\n",
    "    \n",
    "    # data likelihood\n",
    "    predation_obs = pm.Normal(\"predation\", mu, sigma, observed=frog_data['predation'])\n",
    "    \n",
    "    three_par_idata = pm.sample(chains=4, idata_kwargs={\"log_likelihood\": True})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Model 4: Colour + Length + Weight\n",
    "with pm.Model() as four_par:\n",
    "    # priors\n",
    "    alpha = pm.Normal(\"alpha\", 0, 1)\n",
    "    beta_c = pm.Normal(\"beta_c\", 0, 1)\n",
    "    beta_l = pm.Normal(\"beta_l\", 0, 1)\n",
    "    beta_w = pm.Normal(\"beta_w\", 0, 1)\n",
    "    sigma = pm.Exponential(\"sigma\", 1)\n",
    "    \n",
    "    # linear model\n",
    "    mu = pm.Deterministic(\"mu\", alpha + beta_c*frog_data['colours'] + beta_l*frog_data['lengths'] + beta_w*frog_data['weights'])\n",
    "    \n",
    "    # data likelihood\n",
    "    predation_obs = pm.Normal(\"predation\", mu, sigma, observed=frog_data['predation'])\n",
    "    \n",
    "    four_par_idata = pm.sample(chains=4, idata_kwargs={\"log_likelihood\": True})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Model 5: Colour + Length + Weight + Reproduction\n",
    "with pm.Model() as five_par:\n",
    "    # priors\n",
    "    alpha = pm.Normal(\"alpha\", 0, 1)\n",
    "    beta_c = pm.Normal(\"beta_c\", 0, 1)\n",
    "    beta_l = pm.Normal(\"beta_l\", 0, 1)\n",
    "    beta_w = pm.Normal(\"beta_w\", 0, 1)\n",
    "    beta_r = pm.Normal(\"beta_r\", 0, 1)\n",
    "    sigma = pm.Exponential(\"sigma\", 1)\n",
    "    \n",
    "    # linear model\n",
    "    mu = pm.Deterministic(\"mu\", alpha + beta_c*frog_data['colours'] + beta_l*frog_data['lengths'] + beta_w*frog_data['weights'] + beta_r*frog_data['reproduction'])\n",
    "    \n",
    "    # data likelihood\n",
    "    predation_obs = pm.Normal(\"predation\", mu, sigma, observed=frog_data['predation'])\n",
    "    \n",
    "    five_par_idata = pm.sample(chains=4, idata_kwargs={\"log_likelihood\": True})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Model 6: Polynomial (adding quadratic term)\n",
    "frog_data['reproduction2'] = frog_data['reproduction']**2\n",
    "\n",
    "with pm.Model() as poly_par:\n",
    "    # priors\n",
    "    alpha = pm.Normal(\"alpha\", 0, 1)\n",
    "    beta_c = pm.Normal(\"beta_c\", 0, 1)\n",
    "    beta_l = pm.Normal(\"beta_l\", 0, 1)\n",
    "    beta_w = pm.Normal(\"beta_w\", 0, 1)\n",
    "    beta_w2 = pm.Normal(\"beta_w2\", 0, 1)\n",
    "    beta_r = pm.Normal(\"beta_r\", 0, 1)\n",
    "    sigma = pm.Exponential(\"sigma\", 1)\n",
    "    \n",
    "    # linear model\n",
    "    mu = pm.Deterministic(\"mu\", alpha + beta_c*frog_data['colours'] + beta_l*frog_data['lengths'] + beta_w*frog_data['weights'] + beta_r*frog_data['reproduction'] + beta_w2*frog_data['reproduction2'])\n",
    "    \n",
    "    # data likelihood\n",
    "    predation_obs = pm.Normal(\"predation\", mu, sigma, observed=frog_data['predation'])\n",
    "    \n",
    "    poly_par_idata = pm.sample(chains=4, idata_kwargs={\"log_likelihood\": True})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Extract LPPD for each model\n",
    "lppd_p1 = az.loo(one_par_idata).elpd_loo\n",
    "lppd_p2 = az.loo(two_par_idata).elpd_loo\n",
    "lppd_p3 = az.loo(three_par_idata).elpd_loo\n",
    "lppd_p4 = az.loo(four_par_idata).elpd_loo\n",
    "lppd_p5 = az.loo(five_par_idata).elpd_loo\n",
    "lppd_p6 = az.loo(poly_par_idata).elpd_loo\n",
    "\n",
    "# Create comparison table\n",
    "lppd_comparison = pd.DataFrame({\n",
    "    'Model': ['M1: Intercept Only', \n",
    "              'M2: Colour Only', \n",
    "              'M3: Colour + Length', \n",
    "              'M4: Colour + Length + Weight',\n",
    "              'M5: Colour + Length + Weight + Reproduction',\n",
    "              'M6: Polynomial'\n",
    "              ],\n",
    "    'LPPD': [lppd_p1, lppd_p2, lppd_p3, lppd_p4, lppd_p5, lppd_p6],\n",
    "    'Parameters': [2, 3, 4, 5, 6, 7]\n",
    "})\n",
    "\n",
    "print(lppd_comparison)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Higher LPPD is better** - it means the model assigns higher probability density to the observed data.\n",
    "\n",
    "Looking at our results:\n",
    "\n",
    "1.  **M1 (Intercept Only)**: Poorest LPPD - ignores all predictors\n",
    "2.  **M2 (Colour Only)**:\n",
    "3.  **M3 (Colour + Length)**:\n",
    "4.  **M4 (Colour + Length + Weight)**:\n",
    "5.  **M5 (Colour + Length + Weight + Reproduction)**:\n",
    "6.  **M6 (Polynomial)**: Highest LPPD YAY\n",
    "\n",
    "The posterior distributions of our five parameter model do the best job at predicting our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From LPPD to Model Comparison Metrics\n",
    "\n",
    "LPPD is the foundation for:\n",
    "\n",
    "### 1. WAIC (Widely Applicable Information Criterion)\n",
    "\n",
    "$$\\text{WAIC} = -2(\\text{lppd} - p_{WAIC})$$\n",
    "\n",
    "Where $p_{WAIC}$ is the effective number of parameters (penalty for overfitting).\n",
    "\n",
    "### 2. LOO-CV (Leave-One-Out Cross-Validation)\n",
    "\n",
    "Estimates out-of-sample LPPD by leaving out each observation and predicting it."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Compare models using WAIC and LOO\n",
    "model_dict = {\n",
    "    'one_par': one_par_idata,\n",
    "    'two_par': two_par_idata,\n",
    "    'three_par': three_par_idata,\n",
    "    'four_par': four_par_idata,\n",
    "    'five_par': five_par_idata,\n",
    "    'poly_par': poly_par_idata\n",
    "}\n",
    "\n",
    "# WAIC comparison\n",
    "waic_comparison = az.compare(model_dict, ic='waic')\n",
    "print(\"WAIC Comparison:\")\n",
    "print(waic_comparison)\n",
    "\n",
    "# LOO comparison\n",
    "loo_comparison = az.compare(model_dict, ic='loo')\n",
    "print(\"\\nLOO Comparison:\")\n",
    "print(loo_comparison)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparison vs Model Selection\n",
    "\n",
    "One thing we can do with all of these tools is to perform *model selection*, which means choosing the model with the lowest PSIS/WAIC value. An issue with this idea is maximizing predictive accuracy is not the same is not the same as making inference based on causation. In fact, models that counfound causal inference can make better predictions.\n",
    "\n",
    "Instead, we prefer a concept of *model comparison*, which uses multiple models to understand how different variables influence predictions and when used with a causal model and independencies help us infer causal relationships.\n",
    "\n",
    "Let's go through a simulated example."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# draw dag\n",
    "dag = dagitty.dagitty(\"dag{ A-> C B->C}\")\n",
    "\n",
    "# extract edges for Python plotting\n",
    "edges_r = ro.r('function(d) { e <- edges(d); data.frame(from=e$v, to=e$w) }')(dag)\n",
    "edges = [(str(edges_r[0][i]), str(edges_r[1][i])) for i in range(len(edges_r[0]))]\n",
    "\n",
    "dag_nx = nx.DiGraph(edges)\n",
    "# Draw the DAG\n",
    "pos = nx.spring_layout(dag_nx)\n",
    "nx.draw(dag_nx, pos, with_labels=True, node_color='lightblue',\n",
    "        node_size=1500, arrowsize=20, arrows=True)\n",
    "plt.title(\"Collider DAG: A -> C <- B\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# simulate our data\n",
    "np.random.seed(123)\n",
    "A = np.random.normal(0, 1, 100)\n",
    "B = np.random.normal(0, 1, 100)\n",
    "\n",
    "# effect sizes\n",
    "beta_a = -1.5\n",
    "beta_b = 1.5\n",
    "C = np.random.normal(beta_a*A + beta_b*B, 1)\n",
    "\n",
    "sim_data = {\n",
    "    'A': standardize(A),\n",
    "    'B': standardize(B),\n",
    "    'C': standardize(C)\n",
    "}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "We want to see the effect of A on B"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Model A effect on B\n",
    "with pm.Model() as A_model:\n",
    "    # priors\n",
    "    alpha = pm.Normal(\"alpha\", 0, 1)\n",
    "    bA = pm.Normal(\"bA\", 0, 1)\n",
    "    sigma = pm.Exponential(\"sigma\", 1)\n",
    "\n",
    "    # linear model\n",
    "    mu = pm.Deterministic(\"mu\", alpha + bA*sim_data['A'])\n",
    "\n",
    "    # data likelihood\n",
    "    B_obs = pm.Normal(\"B\", mu, sigma, observed=sim_data['B'])\n",
    "\n",
    "    A_model_idata = pm.sample(chains=4, idata_kwargs={\"log_likelihood\": True})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Model A and C effect on B\n",
    "with pm.Model() as AC_model:\n",
    "    # priors\n",
    "    alpha = pm.Normal(\"alpha\", 0, 1)\n",
    "    bC = pm.Normal(\"bC\", 0, 1)\n",
    "    bA = pm.Normal(\"bA\", 0, 1)\n",
    "    sigma = pm.Exponential(\"sigma\", 1)\n",
    "\n",
    "    # linear model\n",
    "    mu = pm.Deterministic(\"mu\", alpha + bC*sim_data['C'] + bA*sim_data['A'])\n",
    "\n",
    "    # data likelihood\n",
    "    B_obs = pm.Normal(\"B\", mu, sigma, observed=sim_data['B'])\n",
    "\n",
    "    AC_model_idata = pm.sample(chains=4, idata_kwargs={\"log_likelihood\": True})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Lets take a look at the effects of each model, we are expecting that A has no effect on B"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Compare coefficient estimates\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "az.plot_forest(A_model_idata, var_names=['alpha', 'bA', 'sigma'], ax=axes[0])\n",
    "axes[0].set_title('A Model (A -> B)')\n",
    "\n",
    "az.plot_forest(AC_model_idata, var_names=['alpha', 'bA', 'bC', 'sigma'], ax=axes[1])\n",
    "axes[1].set_title('AC Model (A + C -> B)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so in our model with just A, we get what we expect, no effect of A on B, but when we introduce C (a collider), this drastically changes our estimate of the effect of A on B, because we have opened a back door path by including the collider.\n",
    "\n",
    "What model do we use here? A_model or AC_model?\n",
    "\n",
    "Now, lets see how they do at making predictions."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Compare models for prediction\n",
    "collider_models = {\n",
    "    'A_model': A_model_idata,\n",
    "    'AC_model': AC_model_idata\n",
    "}\n",
    "\n",
    "loo_collider = az.compare(collider_models, ic='loo')\n",
    "print(\"LOO Comparison for Collider Models:\")\n",
    "print(loo_collider)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AC_model is the better model at predicting. Which model should we use now? Why is it so much better?\n",
    "\n",
    "If we just went by the methods of model selection, we would pick AC_model, as it is better at predicting out-of-sample B's Why? because conditioning on the collider induces a statistical association, so adds to predictive accuracy. While the AC model is better at predicting it fails causally.\n",
    "\n",
    "Lastly, lets go through these tables -\n",
    "\n",
    "-   WAIC - SE: standard error of WAIC\n",
    "-   dWAIC: difference between each models WAIC and the best WAIC in the set\n",
    "-   dSE: standard error fro the best model\n",
    "-   pWAIC: penalty term - these numbers are close to the number of parameters in the posterior"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
